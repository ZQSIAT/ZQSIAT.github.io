# Welcome
I hope to communicate and study with you.
<br>This is my first study blog, please waiting for my updating. 
<br>I will transfer notes from [**Zhihu**](https://www.zhihu.com/people/zhao-qing-song-68-22/activities) platform to my own personal blog.

# How can you reach me?
Email: ***jack.zhaoqingsong#gmail.com***. Please replace "#" with "@". 
<br>Address: Tongji University, No. 4800 Cao'an Highway, Jiading Campus, Shanghai, P.R.China
<br>My Resume: [2024-10-21-updating](https://aicarrier.feishu.cn/wiki/GxWFwJwsQimlEmk2i6ycQTAVnsh?from=from_copylink)

## News
- [2024/10] **1 Papers** on Video Understanding ([**Learning Discriminative Representations in Videos**](https://github.com/ZQSIAT/AEDC)) are accepted by IEEE Signal Processing Letters, **SPL 2024**.
- [2024/10] I have been invited to serve as a Reviewer for CVPR, **CVPR 2025**.
- [2024/09] **1 Papers** on Video Understanding ([**Open-Vocabulary Online Action Detection**](https://github.com/OpenGVLab/OV-OAD)) are accepted by Advances in Neural Information Processing Systems, **NeurIPS 2024**.
- [2024/08] I have been invited to serve as a Reviewer for AAAI, **AAAI 2025**.
- [2024/05] **1 Paper** on visual classification ([***Code Needs Comments***](https://link.springer.com/article/10.1007/s11263-024-02080-0)) is accepted by International Journal of Computer Vision, **IJCV 2024**.


## Publications
<hr />
<img src="https://i.postimg.cc/4dMR8CCY/overall.png" width="307" height="158"   align="left" hspace="20" vspace="0"/>
Does Video-Text Pretraining Help Open-Vocabulary Online Action Detection?
<font face="Georgia"><I></I></font><font face="Georgia" color="RoyalBlue"><I><B>Qingsong Zhao</B></I></font><font face="Georgia"><I>, Yi Wang, Jilan Xu, Yinan He, Zifan Song, Limin Wang, Yu Qiao, Cairong Zhao</I></font>
Advances in Neural Information Processing Systems, <font face="Georgia" color="RoyalBlue"><I><B>NeurIPS 2024</B></I></font>

[[<font color="RoyalBlue"><B>ğŸ“ƒ Code</B></font>]](https://github.com/OpenGVLab/OV-OAD)

<br>
<img src="https://i.postimg.cc/k5khG7FJ/ijcv-overall.png" width="307" height="158"   align="left" hspace="20" vspace="0"/>
Adaptive Discriminative Regularization for Visual Classification

<font face="Georgia"><I></I></font>**<font face="Georgia" color="RoyalBlue"><I><B>Qingsong Zhao</B></I></font>**<font face="Georgia"><I>, Yi Wang, Cairong Zhao</I></font>
International Journal of Computer Vision, <font face="Georgia" color="RoyalBlue"><I><B>IJCV 2024</B></I></font>
[[<font color="RoyalBlue"><B>ğŸ“ƒ Code</B></font>]](https://github.com/OpenGVLab/OV-OAD)

<br>



# Chaos
## æ•°å­—å›¾åƒå¤„ç†
<br>[2018å¹´04æœˆ10æ—¥ æ•°å­—å›¾åƒå¤„ç†ç¬¬ä¸‰ç« ä½œä¸š å›¾åƒå¢å¼º LoG](https://zhuanlan.zhihu.com/p/35239779)
[**\[code\]**](https://github.com/ZQSIAT/blog_code/blob/master/DIP%20Chapter3%20image%20intensification/image_intensification.cpp)
<br>[2019å¹´07æœˆ30æ—¥ åŒçº¿æ€§æ’å€¼åŸç† å›¾åƒæ—‹è½¬](https://note.youdao.com/share/?token=A70902EBA0E048FCA506853FE72C0AE1&gid=89870316)
<br>[2019å¹´07æœˆ31æ—¥ feature mapä»¥åŠåå·ç§¯çš„å¤§å°è®¡ç®—](http://note.youdao.com/groupshare/?token=C74CA57A7DCA4FD391295628980DF651&gid=89870316)
<br>[2019å¹´07æœˆ31æ—¥ ä¸­å€¼æ»¤æ³¢åŸç†åŠå…¶C++ä»£ç ](http://note.youdao.com/groupshare/?token=76567AC7DAB54DEC804E0626E0380E32&gid=89870316)
<br>[2019å¹´08æœˆ02æ—¥ åŠ æƒä¸­å€¼æ»¤æ³¢åŸç†åŠå…¶å…¬å¼æ¨å¯¼](https://note.youdao.com/share/?token=8FA3D0281A964C1BA3A6C71059284881&gid=89870316)
## æœºå™¨å­¦ä¹ 
[2018å¹´07æœˆ15æ—¥ ç”Ÿç‰©åŒ»å­¦ä¿¡æ¯ å¿ƒç”µæ•°æ®åˆ†ç±»è¯†åˆ«](https://zhuanlan.zhihu.com/p/39771706).
[2021å¹´02æœˆ02æ—¥ äºŒç»´å·ç§¯çš„pythonå®ç°](./docs/convolution.md)
<br>[2021å¹´02æœˆ02æ—¥ softmaxæ¿€æ´»å‡½æ•°ç»“åˆcross entropyæŸå¤±å‡½æ•°çš„åå‘ä¼ æ’­è¿‡ç¨‹è®¡ç®—](http://note.youdao.com/groupshare/?token=60D47E0873964BFFB5982AFDF38B200F&gid=89870316)
<br>[2021å¹´02æœˆ03æ—¥BPç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­å®ç° MNIST](http://note.youdao.com/groupshare/?token=8B3A2602C97549A3A5B565B8D6E6A51A&gid=89870316)









