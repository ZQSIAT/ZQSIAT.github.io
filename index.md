# WelcomeğŸ‘‹ğŸ‘‹ğŸ‘‹
I hope to communicate and study with you.
<br>This is my study blog, waiting for my updating. 
<br>I will transfer notes from [**Zhihu**](https://www.zhihu.com/people/zhao-qing-song-68-22/activities) platform to my own personal blog.

# How can you reach me?âš¡ï¸âš¡ï¸âš¡ï¸
Email: ***zqsiat#gmail.com***. Please replace "#" with "@". 
<br>Address: Shanghai, P.R.China
<!-- <br>My Resume: [2024-10-21-updating](https://aicarrier.feishu.cn/wiki/GxWFwJwsQimlEmk2i6ycQTAVnsh?from=from_copylink) -->

## Newsâœ¨âœ¨âœ¨
- [2025/10] Thrilled to announce Iâ€™ve joined TeleAI as an Algorithm Researcher, where Iâ€™ll be focusing on AI Flow (formerly referred to as æ™ºä¼ ç½‘).ğŸŒ±
- [2025/10] **1 Papers** on AI4SCI ([**ExpVid: A Benchmark for Experiment Video Understanding & Reasoning**](https://arxiv.org/abs/2510.11606)) are submited. ğŸ‰
- [2025/09] **1 Papers** on Deep Learning ([**Person Identify Shift for Privacy-Preserving Person Re-identification**](https://arxiv.org/abs/2207.07311)) are accepted by SCIENCE CHINA Information Sciences, **SCIS CCF-A**.ğŸ‰
- [2025/08] **1 Papers** on Machine Learning ([**DPL++: Advancing the Network Performance via Image and Label Perturbations**](https://github.com/)) are accepted by Transactions on Pattern Analysis and Machine Intelligence, **TPAMI 2025**.ğŸ‰
- [2024/10] **1 Papers** on Video Understanding ([**Learning Discriminative Representations in Videos**](https://github.com/ZQSIAT/AEDC)) are accepted by IEEE Signal Processing Letters, **SPL 2024**.ğŸ‰
- [2024/10] I have been invited to serve as a Reviewer for CVPR, **CVPR 2025**.
- [2024/09] **1 Papers** on Video Understanding ([**Open-Vocabulary Online Action Detection**](https://github.com/OpenGVLab/OV-OAD)) are accepted by Advances in Neural Information Processing Systems, **NeurIPS 2024**.ğŸ‰
- [2024/08] I have been invited to serve as a Reviewer for AAAI, **AAAI 2025**.
- [2024/05] **1 Paper** on visual classification ([***Code Needs Comments***](https://link.springer.com/article/10.1007/s11263-024-02080-0)) is accepted by International Journal of Computer Vision, **IJCV 2024**.ğŸ‰



## Publicationsâ­ï¸â­ï¸â­ï¸
<hr />
<img src="https://i.postimg.cc/4dMR8CCY/overall.png" width="307" height="158"   align="left" hspace="20" vspace="0"/>
Does Video-Text Pretraining Help Open-Vocabulary Online Action Detection?
<font face="Georgia"><I></I></font><font face="Georgia" color="RoyalBlue"><I><B>Qingsong Zhao</B></I></font><font face="Georgia"><I>, Yi Wang, Jilan Xu, Yinan He, Zifan Song, Limin Wang, Yu Qiao, Cairong Zhao</I></font>
Advances in Neural Information Processing Systems, <font face="Georgia" color="RoyalBlue"><I><B>NeurIPS 2024</B></I></font>

[[<font color="RoyalBlue"><B>ğŸ“ƒ Code</B></font>]](https://github.com/OpenGVLab/OV-OAD)

<br>
<img src="https://i.postimg.cc/k5khG7FJ/ijcv-overall.png" width="307" height="158"   align="left" hspace="20" vspace="0"/>
Adaptive Discriminative Regularization for Visual Classification.

<font face="Georgia"><I></I></font>**<font face="Georgia" color="RoyalBlue"><I><B>Qingsong Zhao</B></I></font>**<font face="Georgia"><I>, Yi Wang, Cairong Zhao</I></font>
International Journal of Computer Vision, <font face="Georgia" color="RoyalBlue"><I><B>IJCV 2024</B></I></font>
[[<font color="RoyalBlue"><B>ğŸ“ƒ Paper</B></font>]](https://arxiv.org/abs/2203.00833)

<br>
<img src="https://i.postimg.cc/Yq54dV34/aedc-overall.png" width="307" height="158"   align="left" hspace="20" vspace="0"/>
Learning Discriminative Representations in Videos via Active Embedding Distance Correlation.

<font face="Georgia"><I></I></font>**<font face="Georgia" color="RoyalBlue"><I><B>Qingsong Zhao</B></I></font>**<font face="Georgia"><I>, Yi Wang, Cairong Zhao</I></font>
IEEE SPL <font face="Georgia" color="RoyalBlue"><I><B>SPL 2024</B></I></font>
[[<font color="RoyalBlue"><B>ğŸ“ƒ Code</B></font>]](https://github.com/ZQSIAT/AEDC)


<br>

<img src="https://i.postimg.cc/CxbRXNPc/icra-overall.png" width="307" height="158"   align="left" hspace="20" vspace="0"/>
Unleashing the Potential of Mamba: Boosting a LiDAR 3D Sparse Detector by Using Cross-ModelKnowledge Distillation.

<font face="Georgia"><I>Rui Yu, Runkai Zhao, Jiagen Li, </I></font>**<font face="Georgia" color="RoyalBlue"><I><B>Qingsong Zhao</B></I></font>**<font face="Georgia"><I></I></font>
2025 IEEE International Conference on Robotics and Automation (Under Review) <font face="Georgia" color="RoyalBlue"><I><B>ICRA 2025</B></I></font>
[[<font color="RoyalBlue"><B>ğŸ“ƒ Paper</B></font>]](https://arxiv.org/abs/2409.11018)

<br>

<img src="https://i.postimg.cc/5t1XVCDb/kbs-overall.png" width="307" height="158"   align="left" hspace="20" vspace="0"/>
Exploiting Spatio-Temporal Representation for 3D Human Action Recognition from Depth Map Sequences.

<font face="Georgia"><I>Xiaopeng Ji, </I></font>**<font face="Georgia" color="RoyalBlue"><I><B>Qingsong Zhao</B></I></font>**<font face="Georgia"><I></I></font>
KBS <font face="Georgia" color="RoyalBlue"><I><B>KBS 2021</B></I></font>
[[<font color="RoyalBlue"><B>ğŸ“ƒ Paper</B></font>]](https://ieeexplore.ieee.org/document/8943103)

<br>

<img src="https://i.postimg.cc/02MMdxpR/tmm-overall.png" width="307" height="158"   align="left" hspace="20" vspace="0"/>
A Cuboid CNN Model with an Attention Mechanism for Skeleton-based Action Recognition.

<font face="Georgia"><I>Kaijun Zhu, Ruxin Wang, </I></font>**<font face="Georgia" color="RoyalBlue"><I><B>Qingsong Zhao</B></I></font>**<font face="Georgia"><I></I></font>
IEEETransactions on Multimedia <font face="Georgia" color="RoyalBlue"><I><B>TMM 2020</B></I></font>
[[<font color="RoyalBlue"><B>ğŸ“ƒ Paper</B></font>]](https://ieeexplore.ieee.org/document/8943103)

<br>





# ChaosğŸ”§ğŸ”§ğŸ”§
## æ•°å­—å›¾åƒå¤„ç†
<br>[2018å¹´04æœˆ10æ—¥ æ•°å­—å›¾åƒå¤„ç†ç¬¬ä¸‰ç« ä½œä¸š å›¾åƒå¢å¼º LoG](https://zhuanlan.zhihu.com/p/35239779)
[**\[code\]**](https://github.com/ZQSIAT/blog_code/blob/master/DIP%20Chapter3%20image%20intensification/image_intensification.cpp)
<br>[2019å¹´07æœˆ30æ—¥ åŒçº¿æ€§æ’å€¼åŸç† å›¾åƒæ—‹è½¬](https://note.youdao.com/share/?token=A70902EBA0E048FCA506853FE72C0AE1&gid=89870316)
<br>[2019å¹´07æœˆ31æ—¥ feature mapä»¥åŠåå·ç§¯çš„å¤§å°è®¡ç®—](http://note.youdao.com/groupshare/?token=C74CA57A7DCA4FD391295628980DF651&gid=89870316)
<br>[2019å¹´07æœˆ31æ—¥ ä¸­å€¼æ»¤æ³¢åŸç†åŠå…¶C++ä»£ç ](http://note.youdao.com/groupshare/?token=76567AC7DAB54DEC804E0626E0380E32&gid=89870316)
<br>[2019å¹´08æœˆ02æ—¥ åŠ æƒä¸­å€¼æ»¤æ³¢åŸç†åŠå…¶å…¬å¼æ¨å¯¼](https://note.youdao.com/share/?token=8FA3D0281A964C1BA3A6C71059284881&gid=89870316)
## æœºå™¨å­¦ä¹ ğŸ›ğŸ›ğŸ›
[2018å¹´07æœˆ15æ—¥ ç”Ÿç‰©åŒ»å­¦ä¿¡æ¯ å¿ƒç”µæ•°æ®åˆ†ç±»è¯†åˆ«](https://zhuanlan.zhihu.com/p/39771706).
[2021å¹´02æœˆ02æ—¥ äºŒç»´å·ç§¯çš„pythonå®ç°](./docs/convolution.md)
<br>[2021å¹´02æœˆ02æ—¥ softmaxæ¿€æ´»å‡½æ•°ç»“åˆcross entropyæŸå¤±å‡½æ•°çš„åå‘ä¼ æ’­è¿‡ç¨‹è®¡ç®—](http://note.youdao.com/groupshare/?token=60D47E0873964BFFB5982AFDF38B200F&gid=89870316)
<br>[2021å¹´02æœˆ03æ—¥BPç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­å®ç° MNIST](http://note.youdao.com/groupshare/?token=8B3A2602C97549A3A5B565B8D6E6A51A&gid=89870316)









